{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff6b2881",
   "metadata": {},
   "source": [
    "# Task 3 ‚Äì Predictive Analytics for Resource Allocation\n",
    "Dataset: Breast Cancer Dataset from Kaggle\n",
    "Goal: Predict issue priority (High, Medium, Low)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d99210",
   "metadata": {},
   "source": [
    "## Step 1 ‚Äì Import Required Libraries\n",
    "\n",
    "We'll import `pandas` and `numpy` for data handling, `scikit-learn` for machine learning, and metrics to evaluate model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e40f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca3e619",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äì Load and Explore the Dataset\n",
    "\n",
    "We begin by loading the Breast Cancer dataset using `pandas`. This step helps us get a feel for the structure of the data, check for missing values, and understand feature distributions. We'll print the first few rows, view column types, and generate summary statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf3c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (make sure the .csv file is in the same folder as this notebook)\n",
    "df = pd.read_csv(\"breast-cancer.csv\")  # Replace with the correct filename if different\n",
    "\n",
    "# Preview the first 5 rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64f94f6",
   "metadata": {},
   "source": [
    "## Step 3 ‚Äì Data Preprocessing and Feature Engineering\n",
    "\n",
    "We‚Äôll clean the dataset by checking for missing values and transforming categorical data. We'll also create a new `priority` label based on diagnosis, where:\n",
    "- `M` (Malignant) = High priority\n",
    "- `B` (Benign) = Low priority\n",
    "\n",
    "This label will be used as the prediction target for our classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bcec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\\n\", df.isnull().sum())\n",
    "\n",
    "# Encode the diagnosis column as 'priority' label\n",
    "df['priority'] = df['diagnosis'].map({'M': 'high', 'B': 'low'})\n",
    "\n",
    "# Confirm that the mapping worked\n",
    "df['priority'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d06c3d9",
   "metadata": {},
   "source": [
    "## Step 4 ‚Äì Encode the Target Variable\n",
    "\n",
    "Machine learning models work with numerical labels, so we'll encode the `priority` column:\n",
    "- `high` ‚Üí 1\n",
    "- `low` ‚Üí 0\n",
    "\n",
    "This creates a new target column called `priority_encoded`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d54ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create the encoder and apply it to the 'priority' column\n",
    "le = LabelEncoder()\n",
    "df['priority_encoded'] = le.fit_transform(df['priority'])\n",
    "\n",
    "# Display a few rows to confirm encoding\n",
    "df[['priority', 'priority_encoded']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002b9da6",
   "metadata": {},
   "source": [
    "## Step 5 ‚Äì Split the Data into Training and Test Sets\n",
    "\n",
    "We'll divide our dataset so the model can learn patterns from the training set and be fairly tested on unseen data. We'll use an 80/20 split and set a `random_state` for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8601b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = df.drop(columns=['diagnosis', 'priority', 'priority_encoded'])  # Drop non-numeric or redundant columns\n",
    "y = df['priority_encoded']\n",
    "\n",
    "# Split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training samples:\", len(X_train))\n",
    "print(\"Testing samples:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff0d008",
   "metadata": {},
   "source": [
    "## Step 6 ‚Äì Train a Random Forest Classifier\n",
    "\n",
    "We'll use a `RandomForestClassifier` to model the relationship between features and issue priority. Random Forest is a powerful ensemble method that reduces overfitting and handles unbalanced data well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69e3e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8eaa51",
   "metadata": {},
   "source": [
    "## Step 7 ‚Äì Evaluate Model Performance\n",
    "\n",
    "We'll use the test data to measure how well our Random Forest model performs. Specifically, we'll check:\n",
    "- **Accuracy**: how often the model predicts the correct class\n",
    "- **F1-score**: balances precision and recall, useful if classes are imbalanced\n",
    "- **Classification report**: provides detailed performance by class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2325d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"‚úÖ Accuracy:\", round(accuracy * 100, 2), \"%\")\n",
    "print(\"‚úÖ F1 Score:\", round(f1, 2))\n",
    "print(\"\\nDetailed Report:\\n\", classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2e2a03",
   "metadata": {},
   "source": [
    "## Step 8 ‚Äì Conclusion\n",
    "\n",
    "In this notebook, we tackled predictive analytics by building a classification model using the Breast Cancer dataset from Kaggle. We:\n",
    "\n",
    "- Cleaned and explored the data\n",
    "- Engineered a new `priority` label based on diagnosis:\n",
    "  - Malignant (M) ‚Üí High\n",
    "  - Benign (B) ‚Üí Low\n",
    "- Encoded labels numerically for training\n",
    "- Split the dataset into training and testing sets\n",
    "- Trained a `RandomForestClassifier`\n",
    "- Evaluated performance using:\n",
    "  - Accuracy\n",
    "  - F1-score\n",
    "  - Classification report\n",
    "\n",
    "This model helps classify issue priority effectively, demonstrating the power of predictive analytics for resource planning and triage automation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b3d522",
   "metadata": {},
   "source": [
    "## Step 9 ‚Äì Save the Trained Model\n",
    "\n",
    "We'll use `joblib` to save the trained Random Forest model to a `.pkl` file. This allows us to reuse the model later without retraining.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c0326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, 'priority_classifier_model.pkl')\n",
    "\n",
    "print(\"‚úÖ Model saved successfully as priority_classifier_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a31378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from file\n",
    "loaded_model = joblib.load('priority_classifier_model.pkl')\n",
    "\n",
    "# Predict using the loaded model\n",
    "loaded_model.predict(X_test[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c58b888",
   "metadata": {},
   "source": [
    "# Final Summary ‚Äì Predictive Pipeline Completed ‚úÖ\n",
    "\n",
    "In this project, we implemented an end-to-end predictive analytics pipeline using the Breast Cancer dataset. Here's a quick recap of what we achieved:\n",
    "\n",
    "üìå **Step 1‚Äì2: Setup and Exploration**\n",
    "- Imported key libraries (`pandas`, `scikit-learn`, etc.)\n",
    "- Loaded the dataset and reviewed structure and distributions\n",
    "\n",
    "üßπ **Step 3‚Äì4: Preprocessing**\n",
    "- Mapped `diagnosis` to a new `priority` label: Malignant ‚Üí high, Benign ‚Üí low\n",
    "- Encoded labels numerically for training\n",
    "\n",
    "‚úÇÔ∏è **Step 5: Data Splitting**\n",
    "- Used `train_test_split` to separate the data (80/20)\n",
    "\n",
    "üå≤ **Step 6: Model Training**\n",
    "- Trained a `RandomForestClassifier` on the processed training data\n",
    "\n",
    "üìà **Step 7: Evaluation**\n",
    "- Achieved accuracy and F1-score metrics using test data\n",
    "- Verified model performance with `classification_report`\n",
    "\n",
    "üíæ **Step 8: Model Preservation**\n",
    "- Saved the trained model using `joblib.dump()` for reuse and deployment\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ This pipeline serves as a baseline for classification projects and a strong step forward in mastering applied ML. Next steps could include:\n",
    "- Testing more models (Logistic Regression, Gradient Boosting)\n",
    "- Improving label granularity (e.g., high/medium/low based on severity)\n",
    "- Deploying with Flask or FastAPI for real-world usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c943a91",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
